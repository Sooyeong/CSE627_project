{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 627 Project 1\n",
    "### House Price: Advanced Regression Techniques \n",
    "### By Sooyeong Lim, Jason Zhao\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "* Why this competition?\n",
    "\n",
    " The Kaggle competition we chose is \"House Price: Advanced Regression Techniques\". We selected this competition because it satisfies the criterion of good project. Below are few reasons of justification.\n",
    " \n",
    " Firstly, we can practice a lot of feature engineering by doing this project. Feature engineering is very important in Data Science. This dataset contains a lot of features(79) with both quantitative variable and categorical variable. Also, there are many missing variables in the dataset and we can practice imputation skills as well. \n",
    " \n",
    " Second, This project allow us to use the model we learned from class room including Regularized model and Neural Network based model and we think that it is a good idea to do hands on examples. We went further form this baseline model by adding some Ensnblem model or morden technique- Boosting model\n",
    "\n",
    "\n",
    "\n",
    "* Project Timeline and Plan\n",
    "\n",
    " Fit the rough model and had a meeting with Dr. Femiani. After the first meeting, we verified that our approach valid and came up alternative ways to fit the model- NN based model fitting. But it turned out that there is some problem in the feature Engineering. Date and meeting time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Executive Conclusion \n",
    " The fittied model suggest that ~ have a best performance and we ended on \n",
    " First placement-> Second Placement -> Thir Place ment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index \n",
    "\n",
    "\n",
    "* Exploratory Data Analysis\n",
    "* Feature Engineering\n",
    "* Modeling \n",
    "**1. Regularized model, 2. XGBoost, 3. Neural Network Based Model\n",
    "* Results **Provide table of resutls\n",
    "* Limitations/Recommendations\n",
    "* Reference/Resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Exploratory Data analysis is giving a direction of further analysis. We checked that the overall trend of data distribution and relationship between predictors and response variables and setted properdiretion for the feature engineerning and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] A lot of effort in Feature Engineering is needed for this problem. There are many missing observations for the train and test dataset so we imputed by using some trics. We encoded categorical variables. After plotting the dataset that we realized that the relationship between X*Y is not just linear regression. We created seperate Python file to avoid this report lengthy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] Firstly, we fitted Regularized Linear model by using Ridge regression (L2) Regularization and checked it's performance. And tried to apply Elastic net which is ensenble model of L1(Lasso) regression with L2. After fitting this regression file, we also used Neural Network based model by using Pytorch\n",
    "Firt trial, Second trial, Third Trial.. Feature engineering again, Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] The result suggests that ~ shows best performance .... between other method\n",
    "\n",
    "(-Create table and show the result// Leader bord score.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitation/Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] Limitations/Recommendations\n",
    "1. The training data and test dataset have a same length and the performance of the model might be improved that if we can obtain more dataset \n",
    "\n",
    "2. We realize that a lot of domain knowledg is requried \n",
    "\n",
    "3. Feature enginnering/ other types of model is required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] Fidings from EDA- Which feature was included.. how we engineerined. Model fitting and validity of model tracking down. Our efforts to try to improve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference/Resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] https://github.com/Sooyeong/CSE627_project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
